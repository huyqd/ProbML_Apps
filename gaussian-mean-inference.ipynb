{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b031c2",
   "metadata": {},
   "source": [
    "# Gaussian Mean Bayesian Inference: Interactive Visualization\n",
    "\n",
    "This notebook demonstrates Bayesian inference for the mean of a Gaussian distribution with known variance (set to 1), using a Gaussian conjugate prior. We visualize the prior, likelihood, posterior, and posterior predictive distributions with interactive controls for prior and data parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f5ba1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import `numpy`, `jax`, `jax.numpy`, `scipy.stats`, `plotly.graph_objects`, `plotly.subplots`, `ipywidgets`, and `IPython.display` for computation, simulation, interactivity, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5cfd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.stats import norm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "# For LaTeX rendering in Jupyter\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9da63c",
   "metadata": {},
   "source": [
    "## 2. Mathematical Background: Gaussian Mean Inference with Conjugate Prior\n",
    "\n",
    "We consider Bayesian inference for the mean $\\mu$ of a Gaussian distribution with known variance ($\\sigma^2 = 1$).\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "Given $N$ i.i.d. samples $x_1, \\ldots, x_N \\sim \\mathcal{N}(\\mu, 1)$, the likelihood for $\\mu$ is:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mu) = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2}\\right)\n",
    "$$\n",
    "\n",
    "### Prior: Gaussian on Mean\n",
    "\n",
    "We place a Gaussian prior on $\\mu$:\n",
    "$$\n",
    "p(\\mu) = \\mathcal{N}(\\mu \\mid m, v)\n",
    "$$\n",
    "\n",
    "### Posterior\n",
    "\n",
    "By conjugacy, the posterior is also Gaussian:\n",
    "$$\n",
    "p(\\mu \\mid \\mathbf{x}) = \\mathcal{N}(\\mu \\mid m', v')\n",
    "$$\n",
    "where\n",
    "$$\n",
    "v' = \\left(\\frac{N}{1} + \\frac{1}{v}\\right)^{-1}, \\qquad m' = v' \\left(\\frac{N \\bar{x}}{1} + \\frac{m}{v}\\right)\n",
    "$$\n",
    "with $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i$.\n",
    "\n",
    "### Posterior Predictive\n",
    "\n",
    "The predictive density for a new $x^*$ is:\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\int p(x^* \\mid \\mu) p(\\mu \\mid \\mathbf{x}) d\\mu = \\mathcal{N}(x^* \\mid m', v' + 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d86ad",
   "metadata": {},
   "source": [
    "## 3. Set Parameters (Interactive Controls)\n",
    "\n",
    "Use the sliders below to set the number of data points $N$, the true mean $\\mu$, and (optionally) the Gaussian prior parameters $m$ and $v$. Toggle the conjugate prior on/off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92dcedc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8841b8f1aa9145dda58ada55297a7de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=30, description='N (data):', min=1), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data sliders\n",
    "N_slider = widgets.IntSlider(value=30, min=1, max=100, step=1, description=\"N (data):\")\n",
    "mu_slider = widgets.FloatSlider(\n",
    "    value=0.0, min=-3.0, max=3.0, step=0.1, description=\"μ (true):\"\n",
    ")\n",
    "\n",
    "# Conjugate prior toggle\n",
    "cp_checkbox = widgets.Checkbox(value=False, description=\"Conjugate Prior?\")\n",
    "\n",
    "# Prior parameter sliders\n",
    "m_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description=\"m (prior mean):\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "v_slider = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.01,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description=\"v (prior var):\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "\n",
    "def prior_box(cp):\n",
    "    if cp:\n",
    "        return widgets.HBox([m_slider, v_slider])\n",
    "    else:\n",
    "        return widgets.HTML(\"\")\n",
    "\n",
    "\n",
    "ui = widgets.VBox(\n",
    "    [\n",
    "        widgets.HBox([N_slider, mu_slider, m_slider, v_slider]),\n",
    "        cp_checkbox,\n",
    "        widgets.interactive_output(prior_box, {\"cp\": cp_checkbox}),\n",
    "    ]\n",
    ")\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dde0b",
   "metadata": {},
   "source": [
    "## 4. Simulate Gaussian Data\n",
    "\n",
    "Simulate $N$ samples from $\\mathcal{N}(\\mu, 1)$ using JAX. Display the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a59bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_gaussian_data(N, mu, rng_seed=0):\n",
    "    key = jax.random.PRNGKey(rng_seed)\n",
    "    X = jax.random.normal(key, shape=(N,)) + mu\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28a04f",
   "metadata": {},
   "source": [
    "## 5. Compute Likelihood, Prior, and Posterior\n",
    "\n",
    "Compute the log-likelihood of the data as a function of $\\mu$, and update the Gaussian prior to obtain the posterior parameters.\n",
    "\n",
    "**Posterior update equations:**\n",
    "$$\n",
    "v' = \\left(\\frac{N}{1} + \\frac{1}{v}\\right)^{-1}, \\qquad m' = v' \\left(\\frac{N \\bar{x}}{1} + \\frac{m}{v}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3162d07",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "### Bayesian Inference for Gaussian Mean (Known Variance)\n",
    "\n",
    "Suppose we observe data $x_1, \\ldots, x_N$ drawn i.i.d. from a Gaussian distribution with unknown mean $\\mu$ and known variance $\\sigma^2 = 1$.\n",
    "\n",
    "#### **Prior**\n",
    "\n",
    "We place a Gaussian prior on $\\mu$:\n",
    "$$\n",
    "p(\\mu) = \\mathcal{N}(\\mu \\mid m, v) = \\frac{1}{\\sqrt{2\\pi v}} \\exp\\left(-\\frac{1}{2v}(\\mu - m)^2\\right)\n",
    "$$\n",
    "\n",
    "#### **Likelihood**\n",
    "\n",
    "The likelihood of the data given $\\mu$ is:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mu) = \\prod_{i=1}^N \\mathcal{N}(x_i \\mid \\mu, 1) = (2\\pi)^{-N/2} \\exp\\left(-\\frac{1}{2} \\sum_{i=1}^N (x_i - \\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "#### **Posterior Derivation**\n",
    "\n",
    "By Bayes' rule:\n",
    "$$\n",
    "p(\\mu \\mid \\mathbf{x}) \\propto p(\\mathbf{x} \\mid \\mu) \\, p(\\mu)\n",
    "$$\n",
    "\n",
    "Plug in the likelihood and prior:\n",
    "\\begin{align*}\n",
    "\\log p(\\mu \\mid \\mathbf{x}) &= \\log p(\\mathbf{x} \\mid \\mu) + \\log p(\\mu) + \\text{const} \\\\\n",
    "&= -\\frac{1}{2} \\sum_{i=1}^N (x_i - \\mu)^2 - \\frac{1}{2v} (\\mu - m)^2 + \\text{const}\n",
    "\\end{align*}\n",
    "\n",
    "Expand and collect terms in $\\mu$:\n",
    "\\begin{align*}\n",
    "-\\frac{1}{2} \\sum_{i=1}^N (x_i - \\mu)^2 &= -\\frac{1}{2} \\left( \\sum_{i=1}^N x_i^2 - 2\\mu \\sum_{i=1}^N x_i + N\\mu^2 \\right) \\\\\n",
    "-\\frac{1}{2v} (\\mu - m)^2 &= -\\frac{1}{2v} (\\mu^2 - 2m\\mu + m^2)\n",
    "\\end{align*}\n",
    "\n",
    "Combine quadratic and linear terms in $\\mu$:\n",
    "\\begin{align*}\n",
    "\\log p(\\mu \\mid \\mathbf{x}) &= -\\frac{N}{2} \\mu^2 + \\mu \\sum_{i=1}^N x_i -\\frac{1}{2v} \\mu^2 + \\frac{m}{v} \\mu + \\text{const} \\\\\n",
    "&= -\\frac{1}{2} \\left( N + \\frac{1}{v} \\right) \\mu^2 + \\left( \\sum_{i=1}^N x_i + \\frac{m}{v} \\right) \\mu + \\text{const}\n",
    "\\end{align*}\n",
    "\n",
    "This is the log of a Gaussian in $\\mu$, so the posterior is Gaussian:\n",
    "$$\n",
    "p(\\mu \\mid \\mathbf{x}) = \\mathcal{N}(\\mu \\mid m', v')\n",
    "$$\n",
    "where\n",
    "$$\n",
    "v' = \\left( N + \\frac{1}{v} \\right)^{-1}\n",
    "$$\n",
    "$$\n",
    "m' = v' \\left( \\sum_{i=1}^N x_i + \\frac{m}{v} \\right ) = v' \\left( N \\bar{x} + \\frac{m}{v} \\right )\n",
    "$$\n",
    "with $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i$.\n",
    "\n",
    "**Why use log-likelihood instead of likelihood?**  \n",
    "- The likelihood for Gaussian variance involves products of many small probabilities, which can quickly underflow to zero for moderate $N$.\n",
    "- Taking the logarithm turns products into sums, making computations numerically stable and easier to handle.\n",
    "- Log-likelihood is also more convenient for optimization and plotting, as it avoids extremely small numbers.\n",
    "\n",
    "**How to go from log-likelihood to likelihood:**  \n",
    "- If $\\log p(\\mathbf{x} \\mid \\sigma^2)$ is the log-likelihood, then the likelihood is $p(\\mathbf{x} \\mid \\sigma^2) = \\exp(\\log p(\\mathbf{x} \\mid \\sigma^2))$.\n",
    "- In practice, for plotting or normalization, we often subtract the maximum log-likelihood before exponentiating:  \n",
    "    $$\n",
    "    \\text{likelihood}(\\sigma^2) \\propto \\exp\\left(\\log p(\\mathbf{x} \\mid \\sigma^2) - \\max_{\\sigma^2} \\log p(\\mathbf{x} \\mid \\sigma^2)\\right)\n",
    "    $$\n",
    "    This keeps the values in a numerically safe range.\n",
    "\n",
    "\n",
    "#### **Summary:**\n",
    "\n",
    "- **Prior:** $p(\\mu) = \\mathcal{N}(\\mu \\mid m, v)$  \n",
    "- **Likelihood:** $p(\\mathbf{x} \\mid \\mu) = \\prod_{i=1}^N \\mathcal{N}(x_i \\mid \\mu, 1)$  \n",
    "- **Posterior:** $p(\\mu \\mid \\mathbf{x}) = \\mathcal{N}(\\mu \\mid m', v')$  \n",
    "    with  \n",
    "    $$\n",
    "    v' = \\left( N + \\frac{1}{v} \\right)^{-1}, \\qquad m' = v' \\left( N \\bar{x} + \\frac{m}{v} \\right )\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74a2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_mu(X, mu_grid):\n",
    "    # Compute average log-likelihood for each mu in grid\n",
    "    if len(X) == 0:\n",
    "        return np.zeros_like(mu_grid)\n",
    "    N = len(X)\n",
    "    ll = -0.5 * ((X[:, None] - mu_grid[None, :]) ** 2) - 0.5 * np.log(2 * np.pi)\n",
    "    return ll.sum(axis=0) / N\n",
    "\n",
    "\n",
    "def gaussian_posterior_params(m, v, X):\n",
    "    N = len(X)\n",
    "    if N == 0:\n",
    "        return m, v\n",
    "    xbar = np.mean(X)\n",
    "    v_post = 1.0 / (N / 1.0 + 1.0 / v)\n",
    "    m_post = v_post * (N * xbar / 1.0 + m / v)\n",
    "    return m_post, v_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817775b",
   "metadata": {},
   "source": [
    "## 6. Plot Observed Data and True Distribution\n",
    "\n",
    "Use Plotly to plot a histogram of the observed data and overlay the true Gaussian density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8894ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observed_data(X, mu):\n",
    "    x_grid = np.linspace(-3 + mu, 3 + mu, 250)\n",
    "    fig = go.Figure()\n",
    "    if len(X) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=X,\n",
    "                nbinsx=30,\n",
    "                histnorm=\"probability density\",\n",
    "                name=\"Observed Data\",\n",
    "                opacity=0.5,\n",
    "                marker_color=\"#636EFA\",\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=norm.pdf(x_grid, mu, 1.0),\n",
    "            name=\"True Gaussian\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Observed Data and True Gaussian Density\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"Density\",\n",
    "        width=1000,\n",
    "        height=400,\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "    fig.update_traces(opacity=0.7)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eebb0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b1f4f87b649f1bd07d92d3df60b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=30, description='N (data):', min=1), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dc97cc22aa475ca8fbe774cd3323c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_observed_data_interactive(N, mu, cp, m, v):\n",
    "    X = simulate_gaussian_data(N, mu)\n",
    "    plot_observed_data(X, mu)\n",
    "\n",
    "\n",
    "out = widgets.interactive_output(\n",
    "    plot_observed_data_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"mu\": mu_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"m\": m_slider,\n",
    "        \"v\": v_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642301f",
   "metadata": {},
   "source": [
    "## 7. Plot Prior, Likelihood, and Posterior for Mean\n",
    "\n",
    "Plot the prior, likelihood, and posterior distributions for $\\mu$ using Plotly. Show how the posterior updates as data and prior parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22aa2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior_likelihood_posterior(X, mu, cp, m, v):\n",
    "    mu_grid = jnp.linspace(-3, 3, 300)\n",
    "    # Likelihood (up to normalization)\n",
    "    ll = log_likelihood_mu(X, mu_grid)\n",
    "    likelihood = jnp.exp(ll - jnp.max(ll))\n",
    "    likelihood /= jnp.trapezoid(likelihood, mu_grid)\n",
    "    # Prior and posterior\n",
    "    if cp:\n",
    "        prior = norm.pdf(mu_grid, m, jnp.sqrt(v))\n",
    "        m_post, v_post = gaussian_posterior_params(m, v, X)\n",
    "        posterior = norm.pdf(mu_grid, m_post, jnp.sqrt(v_post))\n",
    "    else:\n",
    "        prior = jnp.ones_like(mu_grid)\n",
    "        posterior = likelihood\n",
    "    # Plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mu_grid,\n",
    "            y=prior,\n",
    "            name=\"Prior p(μ)\",\n",
    "            line=dict(color=\"#00CC96\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mu_grid,\n",
    "            y=likelihood,\n",
    "            name=\"Likelihood p̂(x|μ)\",\n",
    "            line=dict(color=\"#636EFA\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mu_grid,\n",
    "            y=posterior,\n",
    "            name=\"Posterior p(μ|x)\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig.add_vline(\n",
    "        x=mu,\n",
    "        line_color=\"#222\",\n",
    "        line_dash=\"dot\",\n",
    "        annotation_text=\"True μ\",\n",
    "        annotation_position=\"top\",\n",
    "    )\n",
    "    if cp:\n",
    "        lower = m_post - 1.96 * jnp.sqrt(v_post)\n",
    "        upper = m_post + 1.96 * jnp.sqrt(v_post)\n",
    "        fig.add_vrect(\n",
    "            x0=lower,\n",
    "            x1=upper,\n",
    "            fillcolor=\"rgba(239,85,59,0.15)\",\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "            annotation_text=\"95% CI\",\n",
    "            annotation_position=\"top right\",\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"Prior, Likelihood, and Posterior for μ\",\n",
    "        xaxis_title=\"μ\",\n",
    "        yaxis_title=\"Density (unnormalized)\",\n",
    "        width=1000,\n",
    "        height=400,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.3, xanchor=\"center\", x=0.5),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c013159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b1f4f87b649f1bd07d92d3df60b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=30, description='N (data):', min=1), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d7f8d5dd84f7ba12bb8fcc08f0d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_prior_likelihood_posterior_interactive(N, mu, cp, m, v):\n",
    "    X = simulate_gaussian_data(N, mu)\n",
    "    plot_prior_likelihood_posterior(X, mu, cp, m, v)\n",
    "\n",
    "\n",
    "out2 = widgets.interactive_output(\n",
    "    plot_prior_likelihood_posterior_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"mu\": mu_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"m\": m_slider,\n",
    "        \"v\": v_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f070600",
   "metadata": {},
   "source": [
    "## 8. Plot Posterior Predictive Distribution\n",
    "\n",
    "Plot the posterior predictive density for new data points, using the derived formula. Overlay this on the observed data histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c2845",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "### Posterior Predictive Formula (with Detailed Math)\n",
    "\n",
    "The **posterior predictive distribution** describes the probability of a new data point $x^*$ given the observed data $\\mathbf{x}$, after integrating out the uncertainty in the parameter $\\mu$:\n",
    "\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\int p(x^* \\mid \\mu) \\, p(\\mu \\mid \\mathbf{x}) \\, d\\mu\n",
    "$$\n",
    "\n",
    "For the Gaussian mean inference with known variance ($\\sigma^2 = 1$), and a Gaussian prior $p(\\mu) = \\mathcal{N}(\\mu \\mid m, v)$, the posterior $p(\\mu \\mid \\mathbf{x})$ is also Gaussian:\n",
    "\n",
    "$$\n",
    "p(\\mu \\mid \\mathbf{x}) = \\mathcal{N}(\\mu \\mid m', v')\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "v' = \\left( \\frac{N}{1} + \\frac{1}{v} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "m' = v' \\left( \\frac{N \\bar{x}}{1} + \\frac{m}{v} \\right)\n",
    "$$\n",
    "\n",
    "The likelihood for a new data point is:\n",
    "\n",
    "$$\n",
    "p(x^* \\mid \\mu) = \\mathcal{N}(x^* \\mid \\mu, 1)\n",
    "$$\n",
    "\n",
    "Plugging into the integral:\n",
    "\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\int \\mathcal{N}(x^* \\mid \\mu, 1) \\, \\mathcal{N}(\\mu \\mid m', v') \\, d\\mu\n",
    "$$\n",
    "\n",
    "This integral is the convolution of two Gaussians, which results in another Gaussian:\n",
    "\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\mathcal{N}(x^* \\mid m', v' + 1)\n",
    "$$\n",
    "\n",
    "**Summary:**  \n",
    "- The posterior predictive for a new $x^*$ is a Gaussian with mean $m'$ (the posterior mean of $\\mu$) and variance $v' + 1$ (posterior variance of $\\mu$ plus the known data variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5884115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive_density(x_grid, m_post, v_post):\n",
    "    # Predictive is N(m_post, v_post + 1)\n",
    "    return norm.pdf(x_grid, m_post, np.sqrt(v_post + 1))\n",
    "\n",
    "\n",
    "def plot_posterior_predictive(X, m_post, v_post, mu):\n",
    "    x_grid = np.linspace(-3 + mu, 3 + mu, 250)\n",
    "    fig = go.Figure()\n",
    "    if len(X) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=X,\n",
    "                nbinsx=30,\n",
    "                histnorm=\"probability density\",\n",
    "                name=\"Observed Data\",\n",
    "                opacity=0.5,\n",
    "                marker_color=\"#636EFA\",\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=norm.pdf(x_grid, mu, 1.0),\n",
    "            name=\"True Gaussian\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=posterior_predictive_density(x_grid, m_post, v_post),\n",
    "            name=\"Posterior Predictive\",\n",
    "            line=dict(color=\"#00CC96\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Posterior Predictive Density vs Observed Data\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"Density\",\n",
    "        width=1000,\n",
    "        height=400,\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab56f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b1f4f87b649f1bd07d92d3df60b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=30, description='N (data):', min=1), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbb1d3aa4334d889884194dff039f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_posterior_predictive_interactive(N, mu, cp, m, v):\n",
    "    X = simulate_gaussian_data(N, mu)\n",
    "    if cp:\n",
    "        m_post, v_post = gaussian_posterior_params(m, v, X)\n",
    "        plot_posterior_predictive(X, m_post, v_post, mu)\n",
    "    else:\n",
    "        plot_observed_data(X, mu)\n",
    "\n",
    "\n",
    "out3 = widgets.interactive_output(\n",
    "    plot_posterior_predictive_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"mu\": mu_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"m\": m_slider,\n",
    "        \"v\": v_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec3ac4",
   "metadata": {},
   "source": [
    "## 9. Display Summary and Mathematical Explanation\n",
    "\n",
    "Display a summary of the Bayesian updating process, including the formulas for prior, likelihood, posterior, and predictive distributions. Explain the interpretation of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b070f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(N, mu, cp, m, v, X):\n",
    "    if cp:\n",
    "        m_post, v_post = gaussian_posterior_params(m, v, X)\n",
    "        summary = f\"\"\"\n",
    "**Bayesian Updating for Gaussian Mean:**\n",
    "\n",
    "- **Prior:** $\\\\mu \\\\sim \\\\mathcal{{N}}(m, v)$ with $m = {m:.2f}$, $v = {v:.2f}$\n",
    "- **Data:** $N={N}$, true $\\\\mu={mu:.2f}$, observed $\\\\bar{{x}} = {np.mean(X):.2f}$\n",
    "- **Posterior:** $\\\\mu \\\\mid \\\\mathbf{{x}} \\\\sim \\\\mathcal{{N}}(m', v')$ with\n",
    "  $$\n",
    "  v' = \\\\left(\\\\frac{{N}}{{1}} + \\\\frac{{1}}{{v}}\\\\right)^{{-1}} = {v_post:.3f}, \\\\qquad\n",
    "  m' = v' \\\\left(\\\\frac{{N \\\\bar{{x}}}}{{1}} + \\\\frac{{m}}{{v}}\\\\right) = {m_post:.3f}\n",
    "  $$\n",
    "- **Posterior Predictive:** For new $x^*$,\n",
    "  $$\n",
    "  p(x^* \\\\mid \\\\mathbf{{x}}) = \\\\mathcal{{N}}(x^* \\\\mid m', v' + 1)\n",
    "  $$\n",
    "\"\"\"\n",
    "    else:\n",
    "        summary = f\"\"\"\n",
    "**Likelihood-only Inference (No Prior):**\n",
    "\n",
    "- **Data:** $N={N}$, true $\\\\mu={mu:.2f}$\n",
    "- **Posterior:** Proportional to the likelihood.\n",
    "- **Interpretation:** No prior information is used; inference is based only on observed data.\n",
    "\"\"\"\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c10af5",
   "metadata": {},
   "source": [
    "## 10. Interactive Dashboard for Gaussian Mean Inference\n",
    "\n",
    "Combine all widgets, plots, and explanations into an interactive dashboard that updates as parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb884d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b1f4f87b649f1bd07d92d3df60b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=30, description='N (data):', min=1), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ddac6a8e6d48a4993968ae470927df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gauss_mean_inference_dashboard(N, mu, cp, m, v):\n",
    "    X = simulate_gaussian_data(N, mu)\n",
    "    plot_observed_data(X, mu)\n",
    "    plot_prior_likelihood_posterior(X, mu, cp, m, v)\n",
    "    if cp:\n",
    "        m_post, v_post = gaussian_posterior_params(m, v, X)\n",
    "        plot_posterior_predictive(X, m_post, v_post, mu)\n",
    "    display_summary(N, mu, cp, m, v, X)\n",
    "\n",
    "\n",
    "dashboard_out = widgets.interactive_output(\n",
    "    gauss_mean_inference_dashboard,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"mu\": mu_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"m\": m_slider,\n",
    "        \"v\": v_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(dashboard_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
