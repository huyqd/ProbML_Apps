{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c41d666",
   "metadata": {},
   "source": [
    "# Gamma-Gaussian Bayesian Inference: Interactive Visualization\n",
    "\n",
    "This notebook demonstrates Bayesian inference for the variance (or precision) of a Gaussian distribution using a Gamma prior. We visualize the prior, likelihood, posterior, and posterior predictive distributions with interactive controls for prior and data parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f7eab",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import `numpy`, `jax`, `jax.numpy`, `scipy.stats`, `scipy.special`, `plotly.graph_objects`, `plotly.subplots`, `ipywidgets`, and `IPython.display` for computation, simulation, interactivity, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.stats import gamma, norm\n",
    "from jax.scipy.special import gamma as gamma_func\n",
    "from scipy.stats import gamma as scipy_gamma\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "# For LaTeX rendering in Jupyter\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a53ed",
   "metadata": {},
   "source": [
    "## 2. Mathematical Background: Gamma-Gaussian Conjugacy\n",
    "\n",
    "We consider Bayesian inference for the variance (or precision) of a Gaussian distribution with known mean (assume $\\mu=0$ for simplicity).\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "Given $N$ i.i.d. samples $x_1, \\ldots, x_N \\sim \\mathcal{N}(0, \\sigma^2)$, the likelihood for $\\sigma^2$ (or precision $\\tau = 1/\\sigma^2$) is:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\sigma^2) = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "### Prior: Gamma on Precision\n",
    "\n",
    "We place a Gamma prior on the precision $\\tau = 1/\\sigma^2$:\n",
    "$$\n",
    "p(\\tau) = \\mathrm{Gamma}(\\tau \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\tau^{\\alpha-1} e^{-\\beta \\tau}\n",
    "$$\n",
    "\n",
    "### Posterior\n",
    "\n",
    "By conjugacy, the posterior is also Gamma:\n",
    "$$\n",
    "p(\\tau \\mid \\mathbf{x}) = \\mathrm{Gamma}(\\tau \\mid \\alpha', \\beta')\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha' = \\alpha + \\frac{N}{2}, \\qquad \\beta' = \\beta + \\frac{1}{2} \\sum_{i=1}^N x_i^2\n",
    "$$\n",
    "\n",
    "### Posterior Predictive\n",
    "\n",
    "The predictive density for a new $x^*$ is:\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\int p(x^* \\mid \\tau) p(\\tau \\mid \\mathbf{x}) d\\tau\n",
    "$$\n",
    "which is a scaled Student-$t$ distribution.\n",
    "\n",
    "For $\\mu=0$:\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\frac{\\Gamma(\\alpha'+0.5)}{\\Gamma(\\alpha')}\\frac{1}{\\sqrt{2\\pi\\beta'}} \\left(1 + \\frac{(x^*)^2}{2\\beta'}\\right)^{-(\\alpha'+0.5)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0352b",
   "metadata": {},
   "source": [
    "## 3. Set Parameters (Interactive Controls)\n",
    "\n",
    "Use the sliders below to set the number of data points $N$, the true standard deviation $\\sigma$, and (optionally) the Gamma prior parameters $\\alpha$ and $\\beta$. Toggle the conjugate prior on/off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sliders\n",
    "N_slider = widgets.IntSlider(value=30, min=1, max=100, step=1, description=\"N (data):\")\n",
    "sigma_slider = widgets.FloatSlider(\n",
    "    value=1.0, min=0.01, max=5.0, step=0.05, description=\"σ (true):\"\n",
    ")\n",
    "\n",
    "# Conjugate prior toggle\n",
    "cp_checkbox = widgets.Checkbox(value=False, description=\"Conjugate Prior?\")\n",
    "\n",
    "# Prior parameter sliders\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=1.0, min=0.01, max=3.0, step=0.05, description=\"α (prior):\"\n",
    ")\n",
    "beta_slider = widgets.FloatSlider(\n",
    "    value=1.0, min=0.01, max=3.0, step=0.05, description=\"β (prior):\"\n",
    ")\n",
    "\n",
    "\n",
    "def prior_box(cp):\n",
    "    if cp:\n",
    "        return widgets.HBox([alpha_slider, beta_slider])\n",
    "    else:\n",
    "        return widgets.HTML(\"\")\n",
    "\n",
    "\n",
    "ui = widgets.VBox(\n",
    "    [\n",
    "        widgets.HBox([N_slider, sigma_slider, alpha_slider, beta_slider]),\n",
    "        cp_checkbox,\n",
    "        widgets.interactive_output(prior_box, {\"cp\": cp_checkbox}),\n",
    "    ]\n",
    ")\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c688a38",
   "metadata": {},
   "source": [
    "## 4. Simulate Gaussian Data\n",
    "\n",
    "Simulate $N$ samples from $\\mathcal{N}(0, \\sigma^2)$ using JAX. Display the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_gaussian_data(N, sigma, rng_seed=0):\n",
    "    key = jax.random.PRNGKey(rng_seed)\n",
    "    X = jax.random.normal(key, shape=(N,)) * sigma\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a3515",
   "metadata": {},
   "source": [
    "## 5. Compute Likelihood and Posterior Parameters\n",
    "\n",
    "Compute the log-likelihood of the data as a function of $\\sigma$, and update the Gamma prior to obtain the posterior parameters.\n",
    "\n",
    "**Posterior update equations:**\n",
    "$$\n",
    "\\alpha' = \\alpha + \\frac{N}{2}, \\qquad \\beta' = \\beta + \\frac{1}{2} \\sum_{i=1}^N x_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a2f1a",
   "metadata": {},
   "source": [
    "### Likelihood and posterior\n",
    "\n",
    "Given a Gamma **prior** on the precision $\\tau = 1/\\sigma^2$:\n",
    "$$\n",
    "p(\\tau) = \\mathrm{Gamma}(\\tau \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\tau^{\\alpha-1} e^{-\\beta \\tau}\n",
    "$$\n",
    "- **$\\alpha$ (shape parameter):** Controls the concentration of the prior. Larger $\\alpha$ makes the prior more peaked, expressing stronger prior belief about the precision. Smaller $\\alpha$ makes the prior more diffuse, representing weaker prior information.\n",
    "\n",
    "- **$\\beta$ (rate parameter):** Controls the scale of the prior. Larger $\\beta$ shifts the prior toward lower precision (higher variance), while smaller $\\beta$ shifts it toward higher precision (lower variance).\n",
    "\n",
    "Together, $\\alpha$ and $\\beta$ encode your prior beliefs about the likely values of the precision $\\tau$ before seeing any data.\n",
    "\n",
    "**Typical values:**  \n",
    "- $\\alpha = 1$, $\\beta = 1$ yields an exponential prior (uninformative for precision).\n",
    "- $\\alpha < 1$ and/or $\\beta < 1$ gives a very diffuse prior, expressing high uncertainty.\n",
    "- $\\alpha > 1$, $\\beta > 1$ makes the prior more concentrated, encoding stronger prior beliefs.\n",
    "- In practice, $\\alpha$ and $\\beta$ are often set based on prior knowledge or chosen to be weakly informative (e.g., $\\alpha = 1$, $\\beta = 0.1$).  \n",
    "- For a non-informative (Jeffreys) prior on variance, $\\alpha \\to 0$, $\\beta \\to 0$ (improper prior).  \n",
    "- In this notebook, you can interactively adjust $\\alpha$ and $\\beta$ to see their effect.\n",
    "\n",
    "**Likelihood function:**  \n",
    "Given observed data $\\mathbf{x} = (x_1, \\ldots, x_N)$ and known mean $\\mu=0$, the likelihood for variance $\\sigma^2$ (or precision $\\tau$) is:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\sigma^2) = \\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{x_i^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "or, in terms of precision $\\tau = 1/\\sigma^2$:\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\tau) = (2\\pi)^{-N/2} \\tau^{N/2} \\exp\\left(-\\frac{\\tau}{2} \\sum_{i=1}^N x_i^2\\right)\n",
    "$$\n",
    "\n",
    "- The likelihood expresses how probable the observed data are for different values of $\\sigma^2$ (or $\\tau$).\n",
    "- It is maximized at the sample variance, and becomes more peaked as $N$ increases.  \n",
    "- In Bayesian inference, the likelihood is combined with the prior to form the posterior.\n",
    "\n",
    "**Why use log-likelihood instead of likelihood?**  \n",
    "- The likelihood for Gaussian variance involves products of many small probabilities, which can quickly underflow to zero for moderate $N$.\n",
    "- Taking the logarithm turns products into sums, making computations numerically stable and easier to handle.\n",
    "- Log-likelihood is also more convenient for optimization and plotting, as it avoids extremely small numbers.\n",
    "\n",
    "**How to go from log-likelihood to likelihood:**  \n",
    "- If $\\log p(\\mathbf{x} \\mid \\sigma^2)$ is the log-likelihood, then the likelihood is $p(\\mathbf{x} \\mid \\sigma^2) = \\exp(\\log p(\\mathbf{x} \\mid \\sigma^2))$.\n",
    "- In practice, for plotting or normalization, we often subtract the maximum log-likelihood before exponentiating:  \n",
    "    $$\n",
    "    \\text{likelihood}(\\sigma^2) \\propto \\exp\\left(\\log p(\\mathbf{x} \\mid \\sigma^2) - \\max_{\\sigma^2} \\log p(\\mathbf{x} \\mid \\sigma^2)\\right)\n",
    "    $$\n",
    "    This keeps the values in a numerically safe range.\n",
    "\n",
    "After observing data $\\mathbf{x} = (x_1, \\ldots, x_N)$, the **posterior** is:\n",
    "$$\n",
    "p(\\tau \\mid \\mathbf{x}) = \\mathrm{Gamma}(\\tau \\mid \\alpha', \\beta')\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha' = \\alpha + \\frac{N}{2}, \\qquad \\beta' = \\beta + \\frac{1}{2} \\sum_{i=1}^N x_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df9adb",
   "metadata": {},
   "source": [
    "### Derivation: From Likelihood × Prior to Posterior (Gamma-Gaussian Conjugacy)\n",
    "#### Posterior (by Bayes' rule, up to normalization)\n",
    "$$\n",
    "p(\\tau \\mid \\mathbf{x}) \\propto p(\\mathbf{x} \\mid \\tau) \\, p(\\tau)\n",
    "$$\n",
    "Plug in the likelihood and prior:\n",
    "$$\n",
    "p(\\tau \\mid \\mathbf{x}) \\propto \\tau^{N/2} \\exp\\left(-\\frac{\\tau}{2} S\\right) \\cdot \\tau^{\\alpha-1} e^{-\\beta \\tau}\n",
    "$$\n",
    "where $S = \\sum_{i=1}^N x_i^2$.\n",
    "\n",
    "Combine exponents:\n",
    "$$\n",
    "p(\\tau \\mid \\mathbf{x}) \\propto \\tau^{\\alpha-1 + N/2} \\exp\\left(-\\left(\\beta + \\frac{S}{2}\\right)\\tau\\right)\n",
    "$$\n",
    "\n",
    "#### Recognize as a Gamma distribution\n",
    "This is the unnormalized form of a Gamma:\n",
    "$$\n",
    "\\mathrm{Gamma}(\\tau \\mid \\alpha', \\beta') \\propto \\tau^{\\alpha'-1} e^{-\\beta' \\tau}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\alpha' = \\alpha + \\frac{N}{2}, \\qquad \\beta' = \\beta + \\frac{1}{2} S\n",
    "$$\n",
    "\n",
    "#### Conclusion\n",
    "$$\n",
    "\\boxed{\n",
    "p(\\tau \\mid \\mathbf{x}) = \\mathrm{Gamma}\\left(\\tau \\mid \\alpha + \\frac{N}{2}, \\; \\beta + \\frac{1}{2} \\sum_{i=1}^N x_i^2 \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "**Summary:**  \n",
    "Multiplying the likelihood and prior gives a new Gamma distribution for the posterior over precision $\\tau$, with updated parameters reflecting both prior information and observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_sigma(X, sigma_grid):\n",
    "    # Compute average log-likelihood for each sigma in grid\n",
    "    if len(X) == 0:\n",
    "        return jnp.zeros_like(sigma_grid)\n",
    "    N = len(X)\n",
    "    ll = -0.5 * ((X[:, None] ** 2) / (sigma_grid[None, :] ** 2)) - jnp.log(\n",
    "        sigma_grid[None, :]\n",
    "    )\n",
    "    return ll.sum(axis=0) / N\n",
    "\n",
    "\n",
    "def gamma_posterior_params(alpha, beta, X):\n",
    "    N = len(X)\n",
    "    sumsq = jnp.sum(X**2)\n",
    "    alpha_post = alpha + N / 2\n",
    "    beta_post = beta + 0.5 * sumsq\n",
    "    return alpha_post, beta_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd4dab",
   "metadata": {},
   "source": [
    "## 6. Plot Observed Data and True Distribution\n",
    "\n",
    "Use Plotly to plot a histogram of the observed data and overlay the true Gaussian density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observed_data(X, sigma):\n",
    "    x_grid = jnp.linspace(-3 * sigma, 3 * sigma, 250)\n",
    "    fig = go.Figure()\n",
    "    if len(X) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=X,\n",
    "                nbinsx=30,\n",
    "                histnorm=\"probability density\",\n",
    "                name=\"Observed Data\",\n",
    "                opacity=0.5,\n",
    "                marker_color=\"#636EFA\",\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=norm.pdf(x_grid, 0, sigma),\n",
    "            name=\"True Gaussian\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Observed Data and True Gaussian Density\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"Density\",\n",
    "        width=1200,\n",
    "        height=500,\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "    fig.update_traces(opacity=0.7)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99112333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observed_data_interactive(N, sigma, cp, alpha, beta):\n",
    "    X = simulate_gaussian_data(N, sigma)\n",
    "    plot_observed_data(X, sigma)\n",
    "\n",
    "\n",
    "out = widgets.interactive_output(\n",
    "    plot_observed_data_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"sigma\": sigma_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"alpha\": alpha_slider,\n",
    "        \"beta\": beta_slider,\n",
    "    },\n",
    ")\n",
    "\n",
    "display(ui)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29ed42",
   "metadata": {},
   "source": [
    "## 7. Plot Prior, Likelihood, and Posterior for Precision/Variance\n",
    "\n",
    "Plot the prior, likelihood, and posterior distributions for $\\sigma$ (or precision $\\tau = 1/\\sigma^2$) using Plotly. Show how the posterior updates as data and prior parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior_likelihood_posterior(X, sigma, cp, alpha, beta):\n",
    "    sigma_grid = jnp.linspace(0.01, 4.0, 300)\n",
    "    tau_grid = 1.0 / (sigma_grid**2)\n",
    "    # Likelihood (up to normalization)\n",
    "    ll = log_likelihood_sigma(X, sigma_grid)\n",
    "    likelihood = jnp.exp(ll - np.max(ll))\n",
    "    likelihood /= jnp.trapezoid(likelihood, sigma_grid)\n",
    "    # Prior and posterior\n",
    "    if cp:\n",
    "        prior = gamma.pdf(tau_grid, a=alpha, scale=1 / beta) / (2 * sigma_grid**3)\n",
    "        alpha_post, beta_post = gamma_posterior_params(alpha, beta, X)\n",
    "        posterior = gamma.pdf(tau_grid, a=alpha_post, scale=1 / beta_post) / (\n",
    "            2 * sigma_grid**3\n",
    "        )\n",
    "    else:\n",
    "        prior = jnp.ones_like(sigma_grid)\n",
    "        posterior = likelihood\n",
    "    # Plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sigma_grid,\n",
    "            y=prior,\n",
    "            name=\"Prior p(σ)\",\n",
    "            line=dict(color=\"#00CC96\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sigma_grid,\n",
    "            y=likelihood,\n",
    "            name=\"Likelihood p_hat(x|σ)\",\n",
    "            line=dict(color=\"#636EFA\"),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sigma_grid,\n",
    "            y=posterior,\n",
    "            name=\"Posterior p(σ|x)\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    if cp:\n",
    "        gamma_dist = tfp.distributions.Gamma(concentration=alpha_post, rate=beta_post)\n",
    "        # Compute 95% credible interval for prior over sigma\n",
    "        # Compute 95% credible interval for posterior over sigma\n",
    "        # Posterior over tau: Gamma(alpha_post, beta_post)\n",
    "        # 95% CI for tau: [tau_low, tau_high]\n",
    "        tau_low = gamma_dist.quantile(0.025)\n",
    "        tau_high = gamma_dist.quantile(0.975)\n",
    "        # tau_low = scipy_gamma.ppf(0.025, alpha_post, scale=1 / beta_post)\n",
    "        # tau_high = scipy_gamma.ppf(0.975, alpha_post, scale=1 / beta_post)\n",
    "        # Convert to sigma: sigma = 1 / sqrt(tau)\n",
    "        sigma_low = 1 / np.sqrt(tau_high)\n",
    "        sigma_high = 1 / np.sqrt(tau_low)\n",
    "        fig.add_vrect(\n",
    "            x0=sigma_low,\n",
    "            x1=sigma_high,\n",
    "            fillcolor=\"rgba(0,204,150,0.15)\",\n",
    "            line_width=0,\n",
    "            annotation_text=\"95% CI\",\n",
    "            annotation_position=\"top right\",\n",
    "            annotation=dict(font=dict(size=12, color=\"#00CC96\")),\n",
    "            layer=\"below\",\n",
    "        )\n",
    "    fig.add_vline(\n",
    "        x=sigma,\n",
    "        line_color=\"#222\",\n",
    "        line_dash=\"dot\",\n",
    "        annotation_text=\"True σ\",\n",
    "        annotation_position=\"top\",\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Prior, Likelihood, and Posterior for σ\",\n",
    "        xaxis_title=\"σ\",\n",
    "        yaxis_title=\"Density (unnormalized)\",\n",
    "        width=1200,\n",
    "        height=500,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.3, xanchor=\"center\", x=0.5),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76790749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior_likelihood_posterior_interactive(N, sigma, cp, alpha, beta):\n",
    "    X = simulate_gaussian_data(N, sigma)\n",
    "    plot_prior_likelihood_posterior(X, sigma, cp, alpha, beta)\n",
    "\n",
    "\n",
    "out2 = widgets.interactive_output(\n",
    "    plot_prior_likelihood_posterior_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"sigma\": sigma_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"alpha\": alpha_slider,\n",
    "        \"beta\": beta_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f9933",
   "metadata": {},
   "source": [
    "## 8. Plot Posterior Predictive Distribution\n",
    "\n",
    "Plot the posterior predictive density for new data points, using the derived formula. Overlay this on the observed data histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf192a0",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "### Posterior Predictive Distribution Formulae\n",
    "The posterior predictive for a new $x^*$ is:\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\int p(x^* \\mid \\tau) p(\\tau \\mid \\mathbf{x}) d\\tau\n",
    "$$\n",
    "which evaluates to:\n",
    "$$\n",
    "p(x^* \\mid \\mathbf{x}) = \\frac{\\Gamma(\\alpha'+0.5)}{\\Gamma(\\alpha')} \\frac{1}{\\sqrt{2\\pi\\beta'}} \\left(1 + \\frac{(x^*)^2}{2\\beta'}\\right)^{-(\\alpha'+0.5)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5499eec",
   "metadata": {},
   "source": [
    "**Posterior Predictive** in this context refers to the probability distribution for a new data point $x^*$, given the observed data $\\mathbf{x}$ and after updating our beliefs about the model parameters (here, the variance or precision) using Bayes' rule.\n",
    "\n",
    "- It is **not** a point prediction, but a full probability distribution for possible new observations.\n",
    "- It incorporates both the uncertainty in the model parameters (from the posterior) and the randomness of the data-generating process.\n",
    "- Mathematically, it is:\n",
    "  $$\n",
    "  p(x^* \\mid \\mathbf{x}) = \\int p(x^* \\mid \\tau) \\, p(\\tau \\mid \\mathbf{x}) \\, d\\tau\n",
    "  $$\n",
    "  where $p(\\tau \\mid \\mathbf{x})$ is the posterior over precision, and $p(x^* \\mid \\tau)$ is the likelihood for a new $x^*$ given $\\tau$.\n",
    "\n",
    "**Interpretation:**  \n",
    "The posterior predictive gives the likelihood (density) of observing new values $x^*$, taking into account both the observed data and the prior. It reflects our updated uncertainty about the model parameters after seeing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78811df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive_density(x_grid, alpha_post, beta_post):\n",
    "    # Student-t-like predictive for N(0, sigma^2) with Gamma prior on precision\n",
    "    coeff = (\n",
    "        1\n",
    "        / jnp.sqrt(beta_post * 2 * np.pi)\n",
    "        * gamma_func(alpha_post + 0.5)\n",
    "        / gamma_func(alpha_post)\n",
    "    )\n",
    "    return coeff * (1 + x_grid**2 / (2 * beta_post)) ** (-alpha_post - 0.5)\n",
    "\n",
    "\n",
    "def plot_posterior_predictive(X, alpha_post, beta_post, sigma):\n",
    "    x_grid = jnp.linspace(-3 * sigma, 3 * sigma, 250)\n",
    "    fig = go.Figure()\n",
    "    if len(X) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=X,\n",
    "                nbinsx=30,\n",
    "                histnorm=\"probability density\",\n",
    "                name=\"Observed Data\",\n",
    "                opacity=0.5,\n",
    "                marker_color=\"#636EFA\",\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=norm.pdf(x_grid, 0, sigma),\n",
    "            name=\"True Gaussian\",\n",
    "            line=dict(color=\"#EF553B\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_grid,\n",
    "            y=posterior_predictive_density(x_grid, alpha_post, beta_post),\n",
    "            name=\"Posterior Predictive\",\n",
    "            line=dict(color=\"#00CC96\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Posterior Predictive Density vs Observed Data\",\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"Density\",\n",
    "        width=1200,\n",
    "        height=500,\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the interactive posterior predictive distribution using current widget values\n",
    "def plot_posterior_predictive_interactive(N, sigma, cp, alpha, beta):\n",
    "    X = simulate_gaussian_data(N, sigma)\n",
    "    if cp:\n",
    "        alpha_post, beta_post = gamma_posterior_params(alpha, beta, X)\n",
    "        plot_posterior_predictive(X, alpha_post, beta_post, sigma)\n",
    "    else:\n",
    "        # If not using conjugate prior, just plot observed data and true Gaussian\n",
    "        plot_observed_data(X, sigma)\n",
    "\n",
    "\n",
    "out3 = widgets.interactive_output(\n",
    "    plot_posterior_predictive_interactive,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"sigma\": sigma_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"alpha\": alpha_slider,\n",
    "        \"beta\": beta_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d8035",
   "metadata": {},
   "source": [
    "## 9. Display Summary and Mathematical Explanation\n",
    "\n",
    "Display a summary of the Bayesian updating process, including the formulas for prior, likelihood, posterior, and predictive distributions. Explain the interpretation of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b39cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(N, sigma, cp, alpha, beta, X):\n",
    "    if cp:\n",
    "        alpha_post, beta_post = gamma_posterior_params(alpha, beta, X)\n",
    "        summary = f\"\"\"\n",
    "**Bayesian Updating for Gaussian Variance (Precision):**\n",
    "\n",
    "- **Prior:** $\\\\tau = 1/\\\\sigma^2 \\\\sim \\\\mathrm{{Gamma}}(\\\\alpha, \\\\beta)$ with $\\\\alpha = {alpha:.2f}$, $\\\\beta = {beta:.2f}$\n",
    "- **Data:** $N={N}$, true $\\\\sigma={sigma:.2f}$, observed $\\\\sum x_i^2 = {np.sum(X**2):.2f}$\n",
    "- **Posterior:** $\\\\tau \\\\mid \\\\mathbf{{x}} \\\\sim \\\\mathrm{{Gamma}}(\\\\alpha', \\\\beta')$ with\n",
    "  $$\n",
    "  \\\\alpha' = \\\\alpha + \\\\frac{{N}}{{2}} = {alpha_post:.2f}, \\\\qquad\n",
    "  \\\\beta' = \\\\beta + \\\\frac{{1}}{{2}} \\\\sum x_i^2 = {beta_post:.2f}\n",
    "  $$\n",
    "- **Posterior Predictive:** For new $x^*$,\n",
    "  $$\n",
    "  p(x^* \\\\mid \\\\mathbf{{x}}) = \\\\frac{{\\\\Gamma(\\\\alpha'+0.5)}}{{\\\\Gamma(\\\\alpha')}} \\\\frac{{1}}{{\\\\sqrt{{2\\\\pi\\\\beta'}}}} \\\\left(1 + \\\\frac{{(x^*)^2}}{{2\\\\beta'}}\\\\right)^{{-(\\\\alpha'+0.5)}}\n",
    "  $$\n",
    "\"\"\"\n",
    "    else:\n",
    "        summary = f\"\"\"\n",
    "**Likelihood-only Inference (No Prior):**\n",
    "\n",
    "- **Data:** $N={N}$, true $\\\\sigma={sigma:.2f}$\n",
    "- **Posterior:** Proportional to the likelihood.\n",
    "- **Interpretation:** No prior information is used; inference is based only on observed data.\n",
    "\"\"\"\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c313d",
   "metadata": {},
   "source": [
    "## 10. Interactive Dashboard for Gamma Inference\n",
    "\n",
    "Combine all widgets, plots, and explanations into an interactive dashboard that updates as parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_inference_dashboard(N, sigma, cp, alpha, beta):\n",
    "    # Simulate data\n",
    "    X = simulate_gaussian_data(N, sigma)\n",
    "    # Plots\n",
    "    plot_observed_data(X, sigma)\n",
    "    plot_prior_likelihood_posterior(X, sigma, cp, alpha, beta)\n",
    "    if cp:\n",
    "        alpha_post, beta_post = gamma_posterior_params(alpha, beta, X)\n",
    "        plot_posterior_predictive(X, alpha_post, beta_post, sigma)\n",
    "    display_summary(N, sigma, cp, alpha, beta, X)\n",
    "\n",
    "\n",
    "dashboard_out = widgets.interactive_output(\n",
    "    gamma_inference_dashboard,\n",
    "    {\n",
    "        \"N\": N_slider,\n",
    "        \"sigma\": sigma_slider,\n",
    "        \"cp\": cp_checkbox,\n",
    "        \"alpha\": alpha_slider,\n",
    "        \"beta\": beta_slider,\n",
    "    },\n",
    ")\n",
    "display(ui)\n",
    "display(dashboard_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
